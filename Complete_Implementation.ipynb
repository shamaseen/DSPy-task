{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸš€ Retail Analytics Copilot - Complete Implementation\n",
                "## Step-by-Step Code with Explanations\n",
                "\n",
                "This notebook contains **all the code** from the project with detailed explanations for each step.\n",
                "\n",
                "You can run each cell to see how everything works!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸ“¦ Step 1: Install Dependencies\n",
                "\n",
                "First, we need to install all required libraries."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install all dependencies\n",
                "# Run this cell once to set up your environment\n",
                "\n",
                "!pip install dspy-ai>=2.4.0\n",
                "!pip install langgraph>=0.1.0\n",
                "!pip install langchain-core>=0.2.0\n",
                "!pip install pydantic>=2.0.0\n",
                "!pip install click>=8.1.7\n",
                "!pip install rich>=13.7.0\n",
                "!pip install numpy>=1.26.0\n",
                "!pip install pandas>=2.2.0\n",
                "!pip install scikit-learn>=1.3.0\n",
                "!pip install rank-bm25>=0.2.2\n",
                "\n",
                "print(\"âœ… All dependencies installed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸ—„ï¸ Step 2: Database Tool (SQLite Access)\n",
                "\n",
                "This class handles all database operations:\n",
                "- Getting the schema (table structure)\n",
                "- Running SQL queries\n",
                "- Error handling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… SQLiteTool class created!\n",
                        "\n",
                        "Example usage:\n",
                        "  db_tool = SQLiteTool('data/northwind.sqlite')\n",
                        "  schema = db_tool.get_schema()\n",
                        "  result = db_tool.execute_query('SELECT * FROM Products LIMIT 5')\n"
                    ]
                }
            ],
            "source": [
                "import sqlite3\n",
                "from typing import List, Dict, Any, Optional\n",
                "\n",
                "class SQLiteTool:\n",
                "    \"\"\"Tool for accessing SQLite database\"\"\"\n",
                "    \n",
                "    def __init__(self, db_path: str):\n",
                "        \"\"\"\n",
                "        Initialize the database tool.\n",
                "        \n",
                "        Args:\n",
                "            db_path: Path to the SQLite database file\n",
                "        \"\"\"\n",
                "        self.db_path = db_path\n",
                "\n",
                "    def get_schema(self) -> str:\n",
                "        \"\"\"\n",
                "        Get the database schema (table names and columns).\n",
                "        This is used by the AI to understand what's in the database.\n",
                "        \n",
                "        Returns:\n",
                "            String describing all tables and their columns\n",
                "        \"\"\"\n",
                "        conn = sqlite3.connect(self.db_path)\n",
                "        cursor = conn.cursor()\n",
                "        \n",
                "        # Get list of all tables\n",
                "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
                "        tables = cursor.fetchall()\n",
                "        \n",
                "        schema_str = \"\"\n",
                "        for table in tables:\n",
                "            table_name = table[0]\n",
                "            # Get column information for each table\n",
                "            cursor.execute(f\"PRAGMA table_info('{table_name}');\")\n",
                "            columns = cursor.fetchall()\n",
                "            \n",
                "            schema_str += f\"Table: {table_name}\\n\"\n",
                "            for col in columns:\n",
                "                # col[1] is column name, col[2] is data type\n",
                "                schema_str += f\"  - {col[1]} ({col[2]})\\n\"\n",
                "            schema_str += \"\\n\"\n",
                "            \n",
                "        conn.close()\n",
                "        return schema_str\n",
                "\n",
                "    def execute_query(self, query: str) -> Dict[str, Any]:\n",
                "        \"\"\"\n",
                "        Execute a SQL query and return results.\n",
                "        \n",
                "        Args:\n",
                "            query: SQL query string\n",
                "            \n",
                "        Returns:\n",
                "            Dictionary with columns, rows, and any error\n",
                "        \"\"\"\n",
                "        try:\n",
                "            conn = sqlite3.connect(self.db_path)\n",
                "            cursor = conn.cursor()\n",
                "            cursor.execute(query)\n",
                "            \n",
                "            # Get column names from the result\n",
                "            columns = [description[0] for description in cursor.description]\n",
                "            rows = cursor.fetchall()\n",
                "            \n",
                "            conn.close()\n",
                "            return {\n",
                "                \"columns\": columns,\n",
                "                \"rows\": rows,\n",
                "                \"error\": None\n",
                "            }\n",
                "        except Exception as e:\n",
                "            # If there's an error, return it\n",
                "            return {\n",
                "                \"columns\": [],\n",
                "                \"rows\": [],\n",
                "                \"error\": str(e)\n",
                "            }\n",
                "\n",
                "# Test the tool\n",
                "print(\"âœ… SQLiteTool class created!\")\n",
                "print(\"\\nExample usage:\")\n",
                "print(\"  db_tool = SQLiteTool('data/northwind.sqlite')\")\n",
                "print(\"  schema = db_tool.get_schema()\")\n",
                "print(\"  result = db_tool.execute_query('SELECT * FROM Products LIMIT 5')\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Test the Database Tool"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Database Schema (first 800 characters):\n",
                        "Table: Categories\n",
                        "  - CategoryID (INTEGER)\n",
                        "  - CategoryName (TEXT)\n",
                        "  - Description (TEXT)\n",
                        "  - Picture (BLOB)\n",
                        "\n",
                        "Table: sqlite_sequence\n",
                        "  - name ()\n",
                        "  - seq ()\n",
                        "\n",
                        "Table: CustomerCustomerDemo\n",
                        "  - CustomerID (TEXT)\n",
                        "  - CustomerTypeID (TEXT)\n",
                        "\n",
                        "Table: CustomerDemographics\n",
                        "  - CustomerTypeID (TEXT)\n",
                        "  - CustomerDesc (TEXT)\n",
                        "\n",
                        "Table: Customers\n",
                        "  - CustomerID (TEXT)\n",
                        "  - CompanyName (TEXT)\n",
                        "  - ContactName (TEXT)\n",
                        "  - ContactTitle (TEXT)\n",
                        "  - Address (TEXT)\n",
                        "  - City (TEXT)\n",
                        "  - Region (TEXT)\n",
                        "  - PostalCode (TEXT)\n",
                        "  - Country (TEXT)\n",
                        "  - Phone (TEXT)\n",
                        "  - Fax (TEXT)\n",
                        "\n",
                        "Table: Employees\n",
                        "  - EmployeeID (INTEGER)\n",
                        "  - LastName (TEXT)\n",
                        "  - FirstName (TEXT)\n",
                        "  - Title (TEXT)\n",
                        "  - TitleOfCourtesy (TEXT)\n",
                        "  - BirthDate (DATE)\n",
                        "  - HireDate (DATE)\n",
                        "  - Address (TEXT)\n",
                        "  - City (TEXT)\n",
                        "  - Region (TEXT)\n",
                        "  - PostalCode (TEXT)\n",
                        "  - Coun\n",
                        "\n",
                        "\n",
                        "Test Query: How many products?\n",
                        "Columns: ['product_count']\n",
                        "Result: [(77,)]\n",
                        "Error: None\n"
                    ]
                }
            ],
            "source": [
                "# Create the tool instance\n",
                "db_tool = SQLiteTool('data/northwind.sqlite')\n",
                "\n",
                "# Get and display schema\n",
                "schema = db_tool.get_schema()\n",
                "print(\"Database Schema (first 800 characters):\")\n",
                "print(schema[:800])\n",
                "\n",
                "# Run a test query\n",
                "result = db_tool.execute_query(\"SELECT COUNT(*) as product_count FROM Products\")\n",
                "print(\"\\n\\nTest Query: How many products?\")\n",
                "print(f\"Columns: {result['columns']}\")\n",
                "print(f\"Result: {result['rows']}\")\n",
                "print(f\"Error: {result['error']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸ“š Step 3: Document Retriever (BM25 Search)\n",
                "\n",
                "This class searches through our documentation:\n",
                "- Loads markdown files\n",
                "- Splits them into chunks\n",
                "- Uses BM25 algorithm to find relevant chunks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from typing import List, Dict, Any\n",
                "from rank_bm25 import BM25Okapi\n",
                "import glob\n",
                "\n",
                "class Retriever:\n",
                "    \"\"\"Document retriever using BM25 search algorithm\"\"\"\n",
                "    \n",
                "    def __init__(self, docs_dir: str):\n",
                "        \"\"\"\n",
                "        Initialize the retriever by loading all documents.\n",
                "        \n",
                "        Args:\n",
                "            docs_dir: Directory containing markdown files\n",
                "        \"\"\"\n",
                "        self.docs_dir = docs_dir\n",
                "        self.chunks: List[Dict[str, Any]] = []\n",
                "        self.bm25 = None\n",
                "        self._load_documents()\n",
                "\n",
                "    def _load_documents(self):\n",
                "        \"\"\"\n",
                "        Load all markdown files and split into chunks.\n",
                "        Each chunk gets a unique ID for citation.\n",
                "        \"\"\"\n",
                "        # Find all .md files\n",
                "        file_paths = glob.glob(os.path.join(self.docs_dir, \"*.md\"))\n",
                "        \n",
                "        for file_path in file_paths:\n",
                "            filename = os.path.basename(file_path)\n",
                "            \n",
                "            # Read file content\n",
                "            with open(file_path, 'r', encoding='utf-8') as f:\n",
                "                content = f.read()\n",
                "                \n",
                "            # Split by paragraphs (double newlines)\n",
                "            paragraphs = [p.strip() for p in content.split('\\n\\n') if p.strip()]\n",
                "            \n",
                "            # Create chunks with IDs\n",
                "            for j, para in enumerate(paragraphs):\n",
                "                chunk_id = f\"{filename.replace('.md', '')}::chunk{j}\"\n",
                "                self.chunks.append({\n",
                "                    \"id\": chunk_id,\n",
                "                    \"content\": para,\n",
                "                    \"source\": filename\n",
                "                })\n",
                "\n",
                "        # Initialize BM25 with tokenized corpus\n",
                "        # BM25 works by comparing word frequencies\n",
                "        tokenized_corpus = [chunk[\"content\"].lower().split() for chunk in self.chunks]\n",
                "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
                "\n",
                "    def retrieve(self, query: str, k: int = 3) -> List[Dict[str, Any]]:\n",
                "        \"\"\"\n",
                "        Find the top-k most relevant chunks for a query.\n",
                "        \n",
                "        Args:\n",
                "            query: Search query\n",
                "            k: Number of results to return\n",
                "            \n",
                "        Returns:\n",
                "            List of chunks with scores\n",
                "        \"\"\"\n",
                "        if not self.chunks:\n",
                "            return []\n",
                "            \n",
                "        # Tokenize query\n",
                "        tokenized_query = query.lower().split()\n",
                "        \n",
                "        # Get BM25 scores for all chunks\n",
                "        scores = self.bm25.get_scores(tokenized_query)\n",
                "        \n",
                "        # Get indices of top-k chunks\n",
                "        top_n = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:k]\n",
                "        \n",
                "        # Return top chunks with scores\n",
                "        results = []\n",
                "        for i in top_n:\n",
                "            results.append({\n",
                "                **self.chunks[i],\n",
                "                \"score\": float(scores[i])\n",
                "            })\n",
                "            \n",
                "        return results\n",
                "\n",
                "print(\"âœ… Retriever class created!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Test the Retriever"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create retriever\n",
                "retriever = Retriever('docs')\n",
                "\n",
                "print(f\"Loaded {len(retriever.chunks)} document chunks\")\n",
                "print(\"\\nChunk IDs:\")\n",
                "for chunk in retriever.chunks[:5]:\n",
                "    print(f\"  - {chunk['id']}\")\n",
                "\n",
                "# Test search\n",
                "query = \"return policy beverages\"\n",
                "results = retriever.retrieve(query, k=2)\n",
                "\n",
                "print(f\"\\n\\nSearch Results for: '{query}'\\n\")\n",
                "for i, result in enumerate(results, 1):\n",
                "    print(f\"{i}. Chunk ID: {result['id']}\")\n",
                "    print(f\"   Score: {result['score']:.3f}\")\n",
                "    print(f\"   Content: {result['content'][:100]}...\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸ§  Step 4: DSPy Signatures (AI Module Definitions)\n",
                "\n",
                "DSPy Signatures define what each AI module should do:\n",
                "- **Router**: Classify questions (rag/sql/hybrid)\n",
                "- **Planner**: Extract constraints from docs\n",
                "- **SQL Generator**: Write SQL queries\n",
                "- **Synthesizer**: Create final answers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… All DSPy Signatures defined!\n"
                    ]
                }
            ],
            "source": [
                "import dspy\n",
                "from typing import List, Optional\n",
                "\n",
                "# Signature 1: Router - Classifies the question type\n",
                "class Router(dspy.Signature):\n",
                "    \"\"\"Classify the user question into one of: 'rag', 'sql', 'hybrid'.\"\"\"\n",
                "    \n",
                "    question = dspy.InputField(desc=\"The user's question about retail analytics.\")\n",
                "    classification = dspy.OutputField(desc=\"One of: 'rag', 'sql', 'hybrid'.\")\n",
                "\n",
                "# Signature 2: Planner - Extracts information from documents\n",
                "class Planner(dspy.Signature):\n",
                "    \"\"\"Extract constraints, date ranges, and entities from the question and docs.\"\"\"\n",
                "    \n",
                "    question = dspy.InputField()\n",
                "    retrieved_docs = dspy.InputField(desc=\"Relevant document chunks.\")\n",
                "    plan = dspy.OutputField(desc=\"Step-by-step plan including date ranges, KPIs, and entities.\")\n",
                "\n",
                "# Signature 3: SQL Generator - Writes SQL queries\n",
                "class GenerateSQL(dspy.Signature):\n",
                "    \"\"\"Generate a SQLite query based on the question, schema, and plan.\"\"\"\n",
                "    \n",
                "    question = dspy.InputField()\n",
                "    plan = dspy.InputField(desc=\"Execution plan with constraints and entities.\")\n",
                "    db_schema = dspy.InputField(desc=\"Schema of the available tables.\")\n",
                "    sql_query = dspy.OutputField(desc=\"The SQLite query to answer the question.\")\n",
                "\n",
                "# Signature 4: Synthesizer - Creates final answer\n",
                "class SynthesizeAnswer(dspy.Signature):\n",
                "    \"\"\"Synthesize a final answer based on the question, SQL results, and retrieved documents.\"\"\"\n",
                "    \n",
                "    question = dspy.InputField()\n",
                "    sql_query = dspy.InputField(desc=\"The SQL query executed, if any.\")\n",
                "    sql_result = dspy.InputField(desc=\"The result of the SQL query, if any.\")\n",
                "    retrieved_docs = dspy.InputField(desc=\"Relevant document chunks from the knowledge base.\")\n",
                "    format_hint = dspy.InputField(desc=\"The expected format of the answer (e.g., int, float, list[dict]).\")\n",
                "    \n",
                "    final_answer = dspy.OutputField(desc=\"The answer matching the format hint.\")\n",
                "    explanation = dspy.OutputField(desc=\"A brief explanation (<= 2 sentences).\")\n",
                "    citations = dspy.OutputField(desc=\"List of DB tables and doc chunk IDs used.\")\n",
                "\n",
                "print(\"âœ… All DSPy Signatures defined!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### DSPy Modules (Wrap Signatures with ChainOfThought)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Modules wrap signatures with Chain of Thought reasoning\n",
                "# This makes the AI \"think\" before answering\n",
                "\n",
                "class CoT_Router(dspy.Module):\n",
                "    \"\"\"Router module with Chain of Thought\"\"\"\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.prog = dspy.ChainOfThought(Router)\n",
                "    \n",
                "    def forward(self, question):\n",
                "        return self.prog(question=question)\n",
                "\n",
                "class CoT_Planner(dspy.Module):\n",
                "    \"\"\"Planner module with Chain of Thought\"\"\"\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.prog = dspy.ChainOfThought(Planner)\n",
                "    \n",
                "    def forward(self, question, retrieved_docs):\n",
                "        return self.prog(question=question, retrieved_docs=retrieved_docs)\n",
                "\n",
                "class CoT_SQL(dspy.Module):\n",
                "    \"\"\"SQL Generator module with Chain of Thought\"\"\"\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.prog = dspy.ChainOfThought(GenerateSQL)\n",
                "    \n",
                "    def forward(self, question, db_schema, plan=\"\"):\n",
                "        return self.prog(question=question, db_schema=db_schema, plan=plan)\n",
                "\n",
                "class CoT_Synthesizer(dspy.Module):\n",
                "    \"\"\"Synthesizer module with Chain of Thought\"\"\"\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.prog = dspy.ChainOfThought(SynthesizeAnswer)\n",
                "    \n",
                "    def forward(self, question, sql_query, sql_result, retrieved_docs, format_hint):\n",
                "        return self.prog(\n",
                "            question=question,\n",
                "            sql_query=sql_query,\n",
                "            sql_result=sql_result,\n",
                "            retrieved_docs=retrieved_docs,\n",
                "            format_hint=format_hint\n",
                "        )\n",
                "\n",
                "print(\"âœ… All DSPy Modules created!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸ•¸ï¸ Step 5: LangGraph Workflow (The Agent)\n",
                "\n",
                "This is the main agent that connects everything:\n",
                "- 7 nodes (Router, Retriever, Planner, SQL Gen, Executor, Synthesizer, Repair)\n",
                "- Conditional edges based on classification and errors\n",
                "- State management"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import TypedDict, Any, Union\n",
                "from langgraph.graph import StateGraph, END\n",
                "\n",
                "# Define the state that flows through the graph\n",
                "class AgentState(TypedDict):\n",
                "    question: str\n",
                "    format_hint: str\n",
                "    classification: str\n",
                "    plan: str\n",
                "    sql_query: Optional[str]\n",
                "    sql_result: Optional[Dict[str, Any]]\n",
                "    retrieved_docs: List[Dict[str, Any]]\n",
                "    final_answer: Any\n",
                "    explanation: str\n",
                "    citations: List[str]\n",
                "    confidence: float\n",
                "    error: Optional[str]\n",
                "    repair_count: int\n",
                "\n",
                "print(\"âœ… AgentState defined!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class HybridAgent:\n",
                "    \"\"\"Main agent that combines RAG and SQL\"\"\"\n",
                "    \n",
                "    def __init__(self, db_path: str, docs_dir: str):\n",
                "        \"\"\"\n",
                "        Initialize the agent with database and documents.\n",
                "        \n",
                "        Args:\n",
                "            db_path: Path to SQLite database\n",
                "            docs_dir: Directory with markdown documents\n",
                "        \"\"\"\n",
                "        # Initialize tools\n",
                "        self.db_tool = SQLiteTool(db_path)\n",
                "        self.retriever = Retriever(docs_dir)\n",
                "        self.schema = self.db_tool.get_schema()\n",
                "        \n",
                "        # Initialize DSPy modules\n",
                "        self.router = CoT_Router()\n",
                "        self.planner = CoT_Planner()\n",
                "        self.sql_gen = CoT_SQL()\n",
                "        \n",
                "        # Load optimized SQL generator if available\n",
                "        if os.path.exists(\"agent/optimized_sql_gen.json\"):\n",
                "            print(\"Loading optimized SQL generator...\")\n",
                "            self.sql_gen.load(\"agent/optimized_sql_gen.json\")\n",
                "            \n",
                "        self.synthesizer = CoT_Synthesizer()\n",
                "        \n",
                "        # Build the graph\n",
                "        self.app = self.build_graph()\n",
                "    \n",
                "    def build_graph(self):\n",
                "        \"\"\"Build the LangGraph workflow with 7 nodes\"\"\"\n",
                "        workflow = StateGraph(AgentState)\n",
                "        \n",
                "        # Add all 7 nodes\n",
                "        workflow.add_node(\"router\", self.route_question)\n",
                "        workflow.add_node(\"retriever\", self.retrieve_docs)\n",
                "        workflow.add_node(\"planner\", self.plan_execution)\n",
                "        workflow.add_node(\"sql_generator\", self.generate_sql)\n",
                "        workflow.add_node(\"executor\", self.execute_sql)\n",
                "        workflow.add_node(\"synthesizer\", self.synthesize_answer)\n",
                "        workflow.add_node(\"repair\", self.repair_action)\n",
                "        \n",
                "        # Set entry point\n",
                "        workflow.set_entry_point(\"router\")\n",
                "        \n",
                "        # Add conditional edges based on classification\n",
                "        workflow.add_conditional_edges(\n",
                "            \"router\",\n",
                "            self.decide_route,\n",
                "            {\n",
                "                \"rag\": \"retriever\",\n",
                "                \"sql\": \"sql_generator\",\n",
                "                \"hybrid\": \"retriever\"\n",
                "            }\n",
                "        )\n",
                "        \n",
                "        # From retriever, always go to planner\n",
                "        workflow.add_conditional_edges(\n",
                "            \"retriever\",\n",
                "            lambda state: \"planner\",\n",
                "            {\"planner\": \"planner\"}\n",
                "        )\n",
                "        \n",
                "        # From planner, decide based on classification\n",
                "        workflow.add_conditional_edges(\n",
                "            \"planner\",\n",
                "            lambda state: \"sql_generator\" if state[\"classification\"] in [\"sql\", \"hybrid\"] else \"synthesizer\",\n",
                "            {\n",
                "                \"sql_generator\": \"sql_generator\",\n",
                "                \"synthesizer\": \"synthesizer\"\n",
                "            }\n",
                "        )\n",
                "        \n",
                "        # From SQL generator to executor\n",
                "        workflow.add_edge(\"sql_generator\", \"executor\")\n",
                "        \n",
                "        # From executor, check for errors\n",
                "        workflow.add_conditional_edges(\n",
                "            \"executor\",\n",
                "            self.check_execution,\n",
                "            {\n",
                "                \"synthesizer\": \"synthesizer\",\n",
                "                \"repair\": \"repair\"\n",
                "            }\n",
                "        )\n",
                "        \n",
                "        # Repair loop (max 2 retries)\n",
                "        workflow.add_conditional_edges(\n",
                "            \"repair\",\n",
                "            lambda state: \"sql_generator\" if state[\"repair_count\"] <= 2 else \"synthesizer\",\n",
                "            {\n",
                "                \"sql_generator\": \"sql_generator\",\n",
                "                \"synthesizer\": \"synthesizer\"\n",
                "            }\n",
                "        )\n",
                "        \n",
                "        # Final node\n",
                "        workflow.add_edge(\"synthesizer\", END)\n",
                "        \n",
                "        return workflow.compile()\n",
                "\n",
                "    # Node functions below...\n",
                "    def route_question(self, state: AgentState):\n",
                "        \"\"\"Node 1: Classify the question\"\"\"\n",
                "        print(f\"Routing question: {state['question']}\")\n",
                "        try:\n",
                "            pred = self.router(question=state['question'])\n",
                "            classification = pred.classification.lower() if hasattr(pred, 'classification') else \"hybrid\"\n",
                "            if classification not in [\"rag\", \"sql\", \"hybrid\"]:\n",
                "                classification = \"hybrid\"\n",
                "            return {\"classification\": classification}\n",
                "        except Exception as e:\n",
                "            print(f\"Router error: {e}, defaulting to hybrid\")\n",
                "            return {\"classification\": \"hybrid\"}\n",
                "\n",
                "    def decide_route(self, state: AgentState):\n",
                "        \"\"\"Decision function for routing\"\"\"\n",
                "        return state[\"classification\"]\n",
                "\n",
                "    def retrieve_docs(self, state: AgentState):\n",
                "        \"\"\"Node 2: Search documents\"\"\"\n",
                "        print(\"Retrieving docs...\")\n",
                "        docs = self.retriever.retrieve(state[\"question\"])\n",
                "        return {\"retrieved_docs\": docs}\n",
                "\n",
                "    def plan_execution(self, state: AgentState):\n",
                "        \"\"\"Node 3: Extract constraints from docs\"\"\"\n",
                "        print(\"Planning execution...\")\n",
                "        try:\n",
                "            retrieved_docs = str(state.get(\"retrieved_docs\", []))\n",
                "            pred = self.planner(question=state[\"question\"], retrieved_docs=retrieved_docs)\n",
                "            plan = pred.plan if hasattr(pred, 'plan') else str(pred)\n",
                "            return {\"plan\": plan}\n",
                "        except Exception as e:\n",
                "            print(f\"Planner error: {e}, using basic plan\")\n",
                "            return {\"plan\": f\"Answer the question: {state['question']}\"}\n",
                "\n",
                "    def generate_sql(self, state: AgentState):\n",
                "        \"\"\"Node 4: Generate SQL query\"\"\"\n",
                "        print(\"Generating SQL...\")\n",
                "        try:\n",
                "            pred = self.sql_gen(\n",
                "                question=state[\"question\"], \n",
                "                db_schema=self.schema, \n",
                "                plan=state.get(\"plan\", \"\")\n",
                "            )\n",
                "            sql_query = pred.sql_query if hasattr(pred, 'sql_query') else str(pred)\n",
                "            return {\"sql_query\": sql_query}\n",
                "        except Exception as e:\n",
                "            print(f\"SQL generation error: {e}\")\n",
                "            return {\"sql_query\": None, \"error\": f\"SQL generation failed: {str(e)}\"}\n",
                "\n",
                "    def execute_sql(self, state: AgentState):\n",
                "        \"\"\"Node 5: Execute SQL query\"\"\"\n",
                "        print(f\"Executing SQL: {state['sql_query']}\")\n",
                "        result = self.db_tool.execute_query(state[\"sql_query\"])\n",
                "        error = result.get(\"error\")\n",
                "        return {\"sql_result\": result, \"error\": error}\n",
                "\n",
                "    def check_execution(self, state: AgentState):\n",
                "        \"\"\"Check if SQL execution succeeded\"\"\"\n",
                "        if state.get(\"error\"):\n",
                "            print(f\"Execution Error: {state['error']}\")\n",
                "            return \"repair\"\n",
                "        return \"synthesizer\"\n",
                "\n",
                "    def repair_action(self, state: AgentState):\n",
                "        \"\"\"Node 6: Repair failed SQL\"\"\"\n",
                "        print(f\"Repairing... Attempt {state['repair_count'] + 1}\")\n",
                "        new_plan = state.get(\"plan\", \"\") + f\"\\nPrevious SQL failed with error: {state['error']}. Fix the SQL.\"\n",
                "        return {\n",
                "            \"repair_count\": state[\"repair_count\"] + 1,\n",
                "            \"plan\": new_plan,\n",
                "            \"error\": None\n",
                "        }\n",
                "\n",
                "    def synthesize_answer(self, state: AgentState):\n",
                "        \"\"\"Node 7: Create final answer\"\"\"\n",
                "        print(\"Synthesizing answer...\")\n",
                "        \n",
                "        sql_query = state.get(\"sql_query\", \"\")\n",
                "        sql_result = str(state.get(\"sql_result\", \"\"))\n",
                "        retrieved_docs = str(state.get(\"retrieved_docs\", []))\n",
                "        \n",
                "        try:\n",
                "            pred = self.synthesizer(\n",
                "                question=state[\"question\"],\n",
                "                sql_query=sql_query,\n",
                "                sql_result=sql_result,\n",
                "                retrieved_docs=retrieved_docs,\n",
                "                format_hint=state[\"format_hint\"]\n",
                "            )\n",
                "            \n",
                "            final_answer = pred.final_answer if hasattr(pred, 'final_answer') else None\n",
                "            explanation = pred.explanation if hasattr(pred, 'explanation') else \"Generated answer\"\n",
                "            citations = pred.citations if hasattr(pred, 'citations') else []\n",
                "        except Exception as e:\n",
                "            print(f\"Synthesizer error: {e}, using fallback\")\n",
                "            final_answer = \"Error generating answer\"\n",
                "            explanation = f\"Synthesis failed: {str(e)}\"\n",
                "            citations = []\n",
                "        \n",
                "        # Type conversion\n",
                "        try:\n",
                "            if state[\"format_hint\"] == \"int\":\n",
                "                final_answer = int(float(str(final_answer).strip()))\n",
                "            elif state[\"format_hint\"] == \"float\":\n",
                "                final_answer = float(str(final_answer).strip())\n",
                "        except:\n",
                "            pass \n",
                "            \n",
                "        if isinstance(citations, str):\n",
                "            citations = [c.strip() for c in citations.split(',')]\n",
                "            \n",
                "        # Calculate confidence\n",
                "        confidence = 1.0\n",
                "        if state.get(\"repair_count\", 0) > 0:\n",
                "            confidence -= (0.2 * state[\"repair_count\"])\n",
                "        if not citations:\n",
                "            confidence -= 0.2\n",
                "        if confidence < 0:\n",
                "            confidence = 0.0\n",
                "            \n",
                "        return {\n",
                "            \"final_answer\": final_answer,\n",
                "            \"explanation\": explanation,\n",
                "            \"citations\": citations,\n",
                "            \"confidence\": round(confidence, 2)\n",
                "        }\n",
                "    \n",
                "    def invoke(self, state):\n",
                "        \"\"\"Run the agent\"\"\"\n",
                "        return self.app.invoke(state)\n",
                "\n",
                "print(\"âœ… HybridAgent class created!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸŽ“ Step 6: DSPy Optimization (Training)\n",
                "\n",
                "This code optimizes the SQL generator using examples."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from dspy.teleprompt import BootstrapFewShot\n",
                "import json\n",
                "\n",
                "def optimize_sql_generator():\n",
                "    \"\"\"\n",
                "    Optimize the SQL generator using training examples.\n",
                "    This creates a better version with few-shot examples.\n",
                "    \"\"\"\n",
                "    # Define validation metric\n",
                "    def validate_sql(example, pred, trace=None):\n",
                "        \"\"\"Check if SQL is valid\"\"\"\n",
                "        sql = pred.sql_query\n",
                "        return sql is not None and len(sql) > 10 and \"SELECT\" in sql.upper()\n",
                "\n",
                "    # Setup DSPy with local model\n",
                "    lm = dspy.LM(model='ollama/phi3.5:3.8b-mini-instruct-q4_K_M', \n",
                "                 api_base='http://localhost:11434', \n",
                "                 max_tokens=1000)\n",
                "    dspy.settings.configure(lm=lm)\n",
                "    \n",
                "    # Load training examples\n",
                "    with open('train_examples.json', 'r') as f:\n",
                "        raw_data = json.load(f)\n",
                "    \n",
                "    # Get database schema\n",
                "    db_tool = SQLiteTool(\"data/northwind.sqlite\")\n",
                "    schema = db_tool.get_schema()\n",
                "    \n",
                "    # Create training set\n",
                "    trainset = []\n",
                "    for item in raw_data:\n",
                "        trainset.append(dspy.Example(\n",
                "            question=item['question'],\n",
                "            db_schema=schema,\n",
                "            sql_query=item['sql_query']\n",
                "        ).with_inputs('question', 'db_schema'))\n",
                "        \n",
                "    # Create optimizer\n",
                "    teleprompter = BootstrapFewShot(\n",
                "        metric=validate_sql, \n",
                "        max_bootstrapped_demos=4, \n",
                "        max_labeled_demos=4\n",
                "    )\n",
                "    \n",
                "    print(\"Compiling (optimizing) CoT_SQL...\")\n",
                "    optimized_sql_gen = teleprompter.compile(CoT_SQL(), trainset=trainset)\n",
                "    \n",
                "    # Save\n",
                "    optimized_sql_gen.save(\"agent/optimized_sql_gen.json\")\n",
                "    print(\"Optimization complete. Saved to agent/optimized_sql_gen.json\")\n",
                "    \n",
                "    return optimized_sql_gen\n",
                "\n",
                "print(\"âœ… Optimization function defined!\")\n",
                "print(\"\\nTo run optimization:\")\n",
                "print(\"  optimized_sql_gen = optimize_sql_generator()\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸš€ Step 7: Running the Complete Agent\n",
                "\n",
                "Now we can run the full agent on test questions!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_agent_on_questions(batch_file: str, output_file: str):\n",
                "    \"\"\"\n",
                "    Run the agent on a batch of questions.\n",
                "    \n",
                "    Args:\n",
                "        batch_file: Path to JSONL file with questions\n",
                "        output_file: Path to save results\n",
                "    \"\"\"\n",
                "    import json\n",
                "    import logging\n",
                "    \n",
                "    # Setup logging\n",
                "    logging.basicConfig(\n",
                "        filename='agent_trace.log',\n",
                "        level=logging.INFO,\n",
                "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
                "    )\n",
                "    \n",
                "    # Setup DSPy LM\n",
                "    try:\n",
                "        lm = dspy.LM(model='ollama/phi3.5:3.8b-mini-instruct-q4_K_M', \n",
                "                     api_base='http://localhost:11434', \n",
                "                     max_tokens=1000)\n",
                "    except Exception as e:\n",
                "        print(f\"Error: {e}\")\n",
                "        print(\"Make sure Ollama is running: ollama serve\")\n",
                "        print(\"And model is pulled: ollama pull phi3.5:3.8b-mini-instruct-q4_K_M\")\n",
                "        return\n",
                "        \n",
                "    dspy.settings.configure(lm=lm)\n",
                "    \n",
                "    # Initialize agent\n",
                "    agent = HybridAgent(\n",
                "        db_path=\"data/northwind.sqlite\",\n",
                "        docs_dir=\"docs\"\n",
                "    )\n",
                "    \n",
                "    results = []\n",
                "    \n",
                "    # Process each question\n",
                "    with open(batch_file, 'r') as f:\n",
                "        for line in f:\n",
                "            item = json.loads(line)\n",
                "            print(f\"\\nProcessing: {item['id']}\")\n",
                "            \n",
                "            # Create initial state\n",
                "            initial_state = {\n",
                "                \"question\": item[\"question\"],\n",
                "                \"format_hint\": item[\"format_hint\"],\n",
                "                \"classification\": \"\",\n",
                "                \"plan\": \"\",\n",
                "                \"sql_query\": None,\n",
                "                \"sql_result\": None,\n",
                "                \"retrieved_docs\": [],\n",
                "                \"final_answer\": None,\n",
                "                \"explanation\": \"\",\n",
                "                \"citations\": [],\n",
                "                \"confidence\": 0.0,\n",
                "                \"error\": None,\n",
                "                \"repair_count\": 0\n",
                "            }\n",
                "            \n",
                "            # Run agent\n",
                "            final_state = agent.invoke(initial_state)\n",
                "            \n",
                "            logging.info(f\"Processed {item['id']}. Final Answer: {final_state['final_answer']}\")\n",
                "            \n",
                "            # Create output\n",
                "            output = {\n",
                "                \"id\": item[\"id\"],\n",
                "                \"final_answer\": final_state[\"final_answer\"],\n",
                "                \"sql\": final_state[\"sql_query\"] if final_state[\"sql_query\"] else \"\",\n",
                "                \"confidence\": final_state.get(\"confidence\", 0.0),\n",
                "                \"explanation\": final_state[\"explanation\"],\n",
                "                \"citations\": final_state[\"citations\"]\n",
                "            }\n",
                "            results.append(output)\n",
                "            \n",
                "    # Write results\n",
                "    with open(output_file, 'w') as f:\n",
                "        for res in results:\n",
                "            f.write(json.dumps(res) + \"\\n\")\n",
                "            \n",
                "    print(f\"\\nâœ… Done! Results written to {output_file}\")\n",
                "    return results\n",
                "\n",
                "print(\"âœ… Run function defined!\")\n",
                "print(\"\\nTo run the agent:\")\n",
                "print(\"  results = run_agent_on_questions('sample_questions_hybrid_eval.jsonl', 'outputs_hybrid.jsonl')\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸ“Š Step 8: Example Usage\n",
                "\n",
                "Here's how to use everything together:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: Process a single question\n",
                "print(\"\"\"To process a single question:\n",
                "\n",
                "1. Setup DSPy with Ollama:\n",
                "   lm = dspy.LM(model='ollama/phi3.5:3.8b-mini-instruct-q4_K_M', \n",
                "                api_base='http://localhost:11434', max_tokens=1000)\n",
                "   dspy.settings.configure(lm=lm)\n",
                "\n",
                "2. Create agent:\n",
                "   agent = HybridAgent('data/northwind.sqlite', 'docs')\n",
                "\n",
                "3. Run on a question:\n",
                "   state = {\n",
                "       \"question\": \"What was the revenue in June 1997?\",\n",
                "       \"format_hint\": \"float\",\n",
                "       \"classification\": \"\",\n",
                "       \"plan\": \"\",\n",
                "       \"sql_query\": None,\n",
                "       \"sql_result\": None,\n",
                "       \"retrieved_docs\": [],\n",
                "       \"final_answer\": None,\n",
                "       \"explanation\": \"\",\n",
                "       \"citations\": [],\n",
                "       \"confidence\": 0.0,\n",
                "       \"error\": None,\n",
                "       \"repair_count\": 0\n",
                "   }\n",
                "   result = agent.invoke(state)\n",
                "   print(result['final_answer'])\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸŽ¯ Summary\n",
                "\n",
                "### What We Built:\n",
                "\n",
                "1. **SQLiteTool** - Database access\n",
                "2. **Retriever** - Document search with BM25\n",
                "3. **DSPy Signatures** - AI module definitions\n",
                "4. **DSPy Modules** - Chain of Thought wrappers\n",
                "5. **HybridAgent** - 7-node LangGraph workflow\n",
                "6. **Optimization** - BootstrapFewShot training\n",
                "7. **Runner** - Batch processing\n",
                "\n",
                "### How It Works:\n",
                "\n",
                "```\n",
                "Question â†’ Router â†’ Retriever â†’ Planner â†’ SQL Gen â†’ Executor â†’ Synthesizer â†’ Answer\n",
                "                                              â†“ error â†“\n",
                "                                             Repair (x2)\n",
                "```\n",
                "\n",
                "### To Run:\n",
                "\n",
                "```bash\n",
                "# 1. Make sure Ollama is running\n",
                "ollama serve\n",
                "\n",
                "# 2. Pull the model\n",
                "ollama pull phi3.5:3.8b-mini-instruct-q4_K_M\n",
                "\n",
                "# 3. Run the notebook cells in order!\n",
                "```\n",
                "\n",
                "**You now have the complete implementation with explanations!** ðŸŽ‰"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
